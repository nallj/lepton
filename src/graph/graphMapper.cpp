
#include "graphMapper.h"

/* PUBLIC */

graphMapper::graphMapper(std::string input_file) :
  input_file_(input_file) {}

void graphMapper::mapRegionsToGraphNodesAndProduceTraces(
  const graphs_t &graphs,
  ip_params_map_t &ip_params_map,
  region_to_modules_map_t &available_sr_modules,
  region_to_modules_map_t &available_rr_modules,
  ip_to_capable_modules_map_t &ip_to_capable_modules_map,
  moduleSelectionType module_selection_method
) {

  // TODO: This should be derived from configuration parameters, otherwise set to 0.
  auto use_time_as_random_seed = false;
  unsigned random_seed;

  if (use_time_as_random_seed) {
    random_seed = (unsigned)time(0);
  } else {
    random_seed = 7285;
  }

  // Feed the seed to the pseudo-random number generator.
  srand(random_seed);

  auto trace_file_name = input_file_;
  auto dot_pos = input_file_.find_last_of('.');

  // If there is an extension on the file name only use the name before the extension.
  if (dot_pos != std::string::npos) {
    trace_file_name = input_file_.substr(0, dot_pos);
  }

  unsigned graph_id = 0;

  // Use specified mapping approach.
  switch (module_selection_method) {

    // Random selection of available module.
    case moduleSelectionType::random:

      // Perform mapping activities for each graph.
      for (const auto &it : graphs) {
        graph_id++;

        auto all_top_level_nodes = it->getAllTopLevelNodes();

        std::cout << "\n\n>>> Beginning new graph mapping. <<<\n\n";

        // Iteratively travel from every top level node to map every node with a pseudo-randomly chosen region.
        auto traces = mapRegionsToGraphNodesAndProduceTracesIterativeBreadthFirst(
          all_top_level_nodes,
          ip_params_map,
          available_sr_modules,
          available_rr_modules,
          ip_to_capable_modules_map
        );

        auto new_file_name = trace_file_name + "_" + std::to_string(graph_id);

        // Create new trace file (overwrite if necessary) and store traces.
        auto trace_file_handler = fileWriter(new_file_name);
        trace_file_handler.deleteIfExists();

        // Iterate over all produced traces and print a line in the resultant trace file.
        //for (unsigned long i = 0; i < traces.size(); i++) {
        for (const auto trace : traces) {
          //auto trace = traces.at(i);
          auto trace_event = trace->getHumanFriendlyDisplayString();
          trace_file_handler.addSingleLineToEof(trace_event);
        }
      }
      break;

    default:
      throw std::runtime_error("The chosen module mapping method is not yet supported.");
  }

  if (DEBUG_MAP_REGIONS) {
    debugHelper::debugMapRegions(graphs);
  }
}

/* PRIVATE */

// All traces are of the following format:
//   <IP ID>,              // Which IP was needed by the application?
//   <region ID>,          // Which region satisfied the request?
//   <module ID>,          // Which module of the chosen region satisfied the request?
//   <request time>,       // When did the application request this IP?
//   <execution time>,     // How long did the task take to complete?
//   <dependency traces>   // Trace IDs representing tasks that needed to complete before this one started.
//
// Original trace format:
//   <containing region ID>,
//   <module ID>,
//   <request time>,           // When did the application ask?
//   <load start time>,        // When did the library start sending the bitstream (library could be busy servicing other request)
//   <load fulfillment time>,  // When did the bitstream actually get completely loaded
//   <execution time>          // Total clock cycles (in its' clock region) required to finish execution
//
// NOTE: Load startand fulfillment times were scrapped because the purpose of Lepton is to simulate
//   applications running on PR-capable FPGAs and generate traces.  It's not intended to be hyper-
//   realistic.  The load times can be rolled into execution times.
//
// TODO: Consider implementing loading as part of the simulation since it will need to be in Drachma.
//   Once done, amend the trace structure and remove the above note.
//
// What happens when the FPGA application needs some IP
//   1) the need is generated by succeeding prior tasks
//   2) if the ip can fit anywhere the ICAP starts to draw it in
//     - if it can't fit in anywhere the application will call for it when it can free up a suitable space
//   3) after the region has been loaded with the module it begins executing
//   4) once the module is done it goes idle (if there are no other tasks for that ip) or it executes another task (for the same ip)
traces_t graphMapper::mapRegionsToGraphNodesAndProduceTracesIterativeBreadthFirst(
  nodes_list_t available_nodes,
  ip_params_map_t &ip_params_map,
  region_to_modules_map_t &available_sr_modules,
  region_to_modules_map_t &available_rr_modules,
  ip_to_capable_modules_map_t ip_to_capable_modules_map
) {
  _execution_counter = 0;
  traces_t resultant_traces;
  unsigned long trace_id = 0;

  // Priority queue for keeping track of which node with at least one dependency is the nearest
  // to having a dependency completed.
  nodes_map_t nodes_with_pending_dependencies;
  nodes_map_t executing_nodes;

  // Create containers that represent each reconfigurable region.
  auto rr_contents = reconfigurableRegions(available_rr_modules);

  // Repeatedly map each node until the lists of available nodes and nodes with pending dependencies
  // are entirely consumed.
  while (!available_nodes.empty() || !nodes_with_pending_dependencies.empty()) {

    std::cout << "\n\n\n-----------------------------------\nCC Count: " << _execution_counter << "\n";

    std::cout << "\nThere are " << available_nodes.size() << " available nodes, "
              << executing_nodes.size() << " executing nodes, and "
              << nodes_with_pending_dependencies.size() << " nodes waiting on dependencies.\n";

    // These are inconsequential variables supplied to meet the argument signature requirements of
    // the "performActionsOverAllModules" method.
    int long placeholder0;
    std::shared_ptr<graphNode> placeholder1;

    // Update the execution context's of every active module.
    performActionsOverAllModules(
      available_sr_modules,
      rr_contents,
      placeholder0,
      placeholder1,
      moduleIterationActions::updateExecutionContextSr,
      moduleIterationActions::updateExecutionContextRr
    );

    // Remove all completed nodes from the executing list.
    nodeHelper::removeCompletedNodes(executing_nodes);

    // Try to schedule every available task.
    attemptNodeScheduling(
      available_nodes,
      ip_to_capable_modules_map,
      rr_contents,
      executing_nodes,
      ip_params_map,
      trace_id,
      resultant_traces,
      nodes_with_pending_dependencies,
      available_sr_modules
    );

    // Handle nodes with pending dependencies if there are any.
    if (!nodes_with_pending_dependencies.empty()) {
      handleNodesWithPendingDependencies(
        nodes_with_pending_dependencies,
        available_nodes,
        available_sr_modules,
        rr_contents
      );
    }
  }

  std::cout << "--------------------------------------------------------------------------------------\n\n"
            << ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> SIMULATION COMPLETE! <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n";

  int long placeholder0;
  std::shared_ptr<graphNode> placeholder1;

  // Iterate over all modules and set them to inactive status.
  performActionsOverAllModules(
    available_sr_modules,
    rr_contents,
    placeholder0,
    placeholder1,
    moduleIterationActions::setNotActiveSr,
    moduleIterationActions::setNotActiveRr
  );

  std::cout << "== Produced Traces:\n";
  for (auto trace_it = resultant_traces.begin(); trace_it != resultant_traces.end(); ++trace_it) {
    (*trace_it)->printHumanFriendlyDisplay();
  }

  return resultant_traces;
}

void graphMapper::advanceExecutionContextByEarliestFinishingTask(
  region_to_modules_map_t &available_sr_modules,
  reconfigurableRegions &rr_contents
) {
  // Start off with the largest possible value.
  int long least_than_scoreboard = std::numeric_limits<int long>::max();
  std::shared_ptr<graphNode> least_than_reference;

  // Find the active module with the shortest remaining execution time.
  performActionsOverAllModules(
    available_sr_modules,
    rr_contents,
    least_than_scoreboard,
    least_than_reference,
    moduleIterationActions::updateScoreboardSr,
    moduleIterationActions::updateScoreboardRr
  );

  std::cout << "\n\tsoonest to finish has " << least_than_scoreboard << " remaining\n";

  // Fast-forward execution context if the execution of the dependency has not completed yet.
  if (least_than_scoreboard > 0) {
    _execution_counter += least_than_scoreboard;
    std::cout << "\tCC Count incremented to " << _execution_counter << "\n";
  }

  std::cout << "\nEXE CC = " << _execution_counter << "\n";

  std::cout << "TELL ME ABOUT YOURSELF least_than_reference: "
            << least_than_reference.get()
            << "\n";

  std::cout << least_than_reference->getNodeId() << " (ip" << least_than_reference->getIpId() << ")\n";

  // Mark node as completed if it has not already been done so
  if (!least_than_reference->getNodeIsComplete()) {

    std::cout << "Marking least_than_reference node '"
              << least_than_reference->getNodeId()
              << "' as complete since it has not been done so yet.\n";

    least_than_reference->setNodeIsComplete();
  }
}

void graphMapper::attemptNodeScheduling(
  nodes_list_t &available_nodes,
  ip_to_capable_modules_map_t &ip_to_capable_modules_map,
  reconfigurableRegions &rr_contents,
  nodes_map_t &executing_nodes,
  ip_params_map_t &ip_params_map,
  unsigned long &trace_id,
  traces_t &resultant_traces,
  nodes_map_t &nodes_with_pending_dependencies,
  region_to_modules_map_t &available_sr_modules
) {
  for (unsigned i = 0; i < available_nodes.size(); i++) {

    // Get a node and pop the deque.
    auto node = available_nodes.front();
    available_nodes.pop_front();

    std::cout << "\nScheduling task '" << node->getNodeId();

    unsigned node_ip_id = node->getIpId();

    std::cout << "' (with ip" << node_ip_id << ")\n";

    // Search the IP-to-capable modules_map for the corresponding entry to this IP.
    auto capable_modules_entry = ip_to_capable_modules_map.find(node_ip_id);
    if (capable_modules_entry == ip_to_capable_modules_map.end()) {

      std::cout << "ERROR: While mapping modules to graph nodes there was an IP (ID = "
                << node_ip_id
                << ") that did not have a corresponding entry in the IP-to-capable "
                << "modules_map\n\n";
      exit(-1);
    }

    auto &capable_modules = capable_modules_entry->second;
    auto modules_under_consideration = std::vector<std::shared_ptr<availableModule>>(capable_modules);

    unsigned total_modules = capable_modules.size();
    bool module_found = false;

    std::cout << "\tthere are " << total_modules << " total capable modules for the job. { ";
    for (auto &it : modules_under_consideration) {
      std::cout << it->getHumanReadableId() << ", ";
    }
    std::cout << "}\n";

    // Keep searching until a module is chosen or all options are exhausted.
    while (total_modules != 0 && !module_found) {

      // Pick a random capable module to run the task.
      unsigned random_module_index = rand() % static_cast<unsigned>(total_modules);
      auto &random_module = modules_under_consideration[random_module_index];

      bool is_not_static = !random_module->getIsStatic();
      unsigned region_id = random_module->getRegionId();

      // If the module is already busy remove it from consideration.
      if (random_module->getIsActive()) {

        std::cout << "\t'"
                  << random_module->getHumanReadableId()
                  << "' was removed from mapping consideration because it was busy.\n";
        std::cout << "\tthere were "
                  << modules_under_consideration.size()
                  << " capable modules and the one to be removed is at index "
                  << random_module_index << "\n";

        // Remove the unfit random module from consideration.
        modules_under_consideration.erase(modules_under_consideration.begin() + random_module_index);
        total_modules--;

      // If the random module is a module that only works in a busy reconfigurable region remove it from consideration.
      } else if (is_not_static && rr_contents.isResidentModuleActive(region_id)) {

        std::cout << "\t'"
                  << random_module->getHumanReadableId()
                  << "' was removed from mapping consideration because the region is must occupy is busy.\n";
        std::cout << "\tthere were "
                  << modules_under_consideration.size()
                  << " capable modules and the one to be removed is at index "
                  << random_module_index
                  << "\n";

        // remove the unfit random module from consideration
        modules_under_consideration.erase(modules_under_consideration.begin() + random_module_index);
        total_modules--;

      // If the module is ready to accept a task then mark the module as busy and add a trace.
      } else {

        std::cout << "\t'"
                  << random_module->getHumanReadableId()
                  << "' is free and able to accept the task of IP "
                  << node_ip_id
                  << ".\n";

        // Mark as active.
        random_module->setIsActive(true);

        // Insert into the list of executing nodes
        executing_nodes.insert(
          std::pair<std::string, std::shared_ptr<graphNode>>(node->getNodeId(), node)
        );

        // If the module belongs to a reconfigurable region then in needs to now occupy its' container.
        if (is_not_static) {
          //matching_rr->second = random_module;
          rr_contents.assignModuleToRegion(region_id, random_module);
        }
        
        // Assign the node to the module.
        random_module->setCurrentTask(node);

        // Increment the execution counter by one to simulate a restriction wherein a task can only be requested per cycle.
        _execution_counter++;
        std::cout << "\tCC Count incremented to " << _execution_counter << "\n";

        // Choose an execution latency dependent on the IP being mapped to the module.
        auto ip_param = ip_params_map[node_ip_id];
        unsigned random_latency_noise = rand() % ip_param.upper_tolerance_ + ip_param.lower_tolerance_;
        unsigned execution_latency = ip_param.latency_ + random_latency_noise;

        // Set the execution latency for the node.
        node->beginExecution(execution_latency, _execution_counter); //, random_module);

        // TODO: Figure out how to derive the trace's dependent traces and supply them to the object.
        traces_t dependent_traces = node->getDependentApplicationTraces();

        // Create the corresponding trace and add it to the result.
        auto confirmed_trace = std::shared_ptr<applicationTrace>(
          new applicationTrace(
            trace_id++,
            node_ip_id,
            random_module,
            _execution_counter,
            execution_latency,
            dependent_traces
          )
        );
        resultant_traces.push_back(confirmed_trace);

        // Assign newly created application trace to the task node for dependency tracking.
        node->setApplicationTrace(confirmed_trace);

        // Indicate a viable module was found and that a mapping has occurred this loop iteration.
        module_found = true;

        // Add successor nodes to available nodes if it is not mapped to a region and all dependencies are satisfied.
        nodeHelper::makeReadyNodeSuccessorsAvailable(
          node,
          available_nodes,
          nodes_with_pending_dependencies
        );
      }

    } // /Find available module loop.

    // If a suitable module was not found for the task then the node must be re-enqueued.
    if (total_modules == 0) {
      std::cout << "\tThere were no available regions to accept the task.  Putting back into available_nodes for later.\n";

      available_nodes.push_back(node);

      // Need to move the execution context forward if there aren't any nodes with pending dependencies to move the context forward.
      if (nodes_with_pending_dependencies.empty()) {
        advanceExecutionContextByEarliestFinishingTask(available_sr_modules, rr_contents);
      }
    }

  } // /available_nodes for loop.
}

// Fast-forward the execution context to when the earliest finishing task completes.
void graphMapper::handleNodesWithPendingDependencies(
  nodes_map_t &nodes_with_pending_dependencies,
  nodes_list_t &available_nodes,
  region_to_modules_map_t &available_sr_modules,
  reconfigurableRegions &rr_contents
) {
  std::cout << "\nMoving on to the pending dependencies...\npending dep nodes: ("
            << nodes_with_pending_dependencies.size()
            << " total) = { ";

  for (auto it = nodes_with_pending_dependencies.begin(); it != nodes_with_pending_dependencies.end(); ++it) {
    std::cout << (*it).first;
    if (it != nodes_with_pending_dependencies.end()) {
      std::cout << ", ";
    }
  }
  std::cout << " }";

  // Start off with the largest possible value.
  int long least_than_scoreboard = std::numeric_limits<int long>::max();

  std::shared_ptr<graphNode> least_than_reference;
  nodes_map_t::iterator chosen_pending_node_it;

  bool pending_node_chosen = false;

  // Loop through the priority queue's underlying deque and update the execution context.
  for (
    auto it = nodes_with_pending_dependencies.begin();
    it != nodes_with_pending_dependencies.end();
    ++it
  ) {
    auto node_ptr = (*it).second;

    std::cout << "\n\t" << (*it).first << " relationships with... ("
              << ((*it).second->getNodeIsExecuting() ? "OMG IS executing, " : "not executing, ")
              << ((*it).second->getNodeIsComplete() ? "OMG IS completed)\n" : "not complete)\n");

    std::vector<std::shared_ptr<graphNode>> predecessor_nodes = node_ptr->getPredecessorNodes();

    // Loop through all of the waiting node's dependency nodes and update their execution context
    // to see if this node is ready to go.
    for (auto it2 = predecessor_nodes.begin(); it2 != predecessor_nodes.end(); ++it2) {

      std::cout << "\n\t\t* " << (*it2)->getNodeId() << "; (";
      // would require " << << " cycles to complete\n";

      std::cout << ((*it2)->getNodeIsExecuting() ? "OMG IS executing, " : "not executing, ")
                << ((*it2)->getNodeIsComplete() ? "OMG IS completed)\n" : "not complete)\n");

      // If the dependency has been executing then update its' execution context.
      // TODO: Is this necessary anymore since this is in the available_nodes for loop?
      if ((*it2)->getNodeIsExecuting() || (*it2)->getNodeIsComplete()) {

        std::cout << "\t\tcycles_remaining_ before recalculation: "
                  << (*it2)->getCyclesRemaining()
                  << "\n";

        // Update the node's execution context.
        int long cycles_remaining = (*it2)->adjustExecutionLatencyByContextUpdate(_execution_counter);

        std::cout << "\n\t\t" << cycles_remaining << " < " << least_than_scoreboard << "\n";
        if (cycles_remaining < least_than_scoreboard) {

          bool this_node_may_be_chosen = true;

          // If cycles remaining are 0, then all other dependencies must be 0 as well.
          // Otherwise the 0 option will always be chosen introducing deadlock.
          if (cycles_remaining == 0) {
            std::cout << "\t\t\tA zero-remaining option has arisen.  This option may be chosen if all other dependencies are ready to go.\n";

            // TODO: There appears to be a serious problem with this loop.  Let's say you have two
            // predecessors.  If the first one reaches the "adjust execution latency" code, but the
            // second one doesn't, then it2 will not be chosen and the first it3 will be left in an
            // advanced state.  But at the same time, I think I might be wrong and it probably
            // doesn't matter.  Try to create some counter example.
            // THE FIX: Split the adjustExecutionLatencyByContextUpdate into 'calculate' and
            // 'adjust' functions.  Only perform the adjust if you actually choose.  And if you
            // are going to choose a zero, make sure if there are other zeros that the one you choose
            // has the lowest cost for all predecessors (I've been drinking - sorry if this doesn't
            // make complete sense).
            // Or maybe we need to adjust all of the predecessor nodes?  And just remember which one
            // is chosen, if one is chosen.
            for (auto it3 = predecessor_nodes.begin(); it3 != predecessor_nodes.end(); ++it3) {

              std::cout << "\t\t\t\t'" << (*it3)->getNodeId() << "'";

              if (!(*it3)->getNodeIsExecuting() && !(*it3)->getNodeIsComplete()) {

                std::cout << " has not even begun to execute; disqualified.\n";
                this_node_may_be_chosen = false;
                break;
              }

              int long cy_remaining = (*it3)->adjustExecutionLatencyByContextUpdate(_execution_counter);

              std::cout << " has " << cy_remaining << " remaining cycles";

              if (cy_remaining > 0) {
                std::cout << "... This one is disqualified.\n";
                this_node_may_be_chosen = false;
                break;
              }
              std::cout << "\n";
            }
          }

          if (this_node_may_be_chosen) {
            std::cout << "\t\t\tPICKED\n";

            least_than_scoreboard = cycles_remaining;

            least_than_reference = *it2;
            chosen_pending_node_it = it;
            pending_node_chosen = true;
          }
        }

      // If the dependency has not begun executing then do not perform a context update.
      } else {
        std::cout << " still waiting on its' own dependencies to clear.\n";
      }
    }
  }

  // If a pending node was found to be the soonest dependency then fast forward using it.
  if (pending_node_chosen) {

    std::cout << "\n\tPNC: soonest to finish has only " << least_than_scoreboard << " remaining\n";

    // Fast-forward execution context if the execution of the dependency has not completed yet.
    if (least_than_scoreboard > 0)  {
      _execution_counter += least_than_scoreboard;
      std::cout << "\tCC Count incremented to " << _execution_counter << "\n";
    }

    std::cout << "\nNEXT EXE CC = " << _execution_counter << "\n";

    std::cout << "TELL ME ABOUT YOURSELF least_than_reference: ";
    std::cout << least_than_reference->getNodeId()
              << " (ip"
              << least_than_reference->getIpId()
              << ")\n";

    std::cout << "TELL ME ABOUT YOURSELF chosen_pending_node_it: ";
    std::cout << (*chosen_pending_node_it).second->getNodeId()
              << " (ip"
              << (*chosen_pending_node_it).second->getIpId()
              << ")\n";

    // Mark node as completed if it has not already been done so.
    if (!least_than_reference->getNodeIsComplete()) {

      std::cout << "Marking least_than_reference node '" << least_than_reference->getNodeId()
                << "' as complete since it has not been done so yet.\n";

      least_than_reference->setNodeIsComplete();
    }

    // If the node no longer has any dependencies then remove it from the pending dependency list and get added to available nodes.
    if ((*chosen_pending_node_it).second->allDependenciesSatisfied()) {

      std::cout << "Removing chosen_pending_node_it node'"
                << (*chosen_pending_node_it).second->getNodeId()
                << "' from the nodes_with_pending_dependencies list and adding to available_nodes list.\n";

      available_nodes.push_back((*chosen_pending_node_it).second);
      nodes_with_pending_dependencies.erase(chosen_pending_node_it);
    }

  // If no pending node was found to be the soonest dependency to finish then choose an executing
  // node from the executing_nodes list with the shortest remaining execution time to fast forward.
  } else {
    advanceExecutionContextByEarliestFinishingTask(available_sr_modules, rr_contents);
  }
}

/////////////////
// TODO: F.60: Prefer T* over T& when "no argument" is a valid option.
/////////////////

// Loop through all static modules and RR content modules and execute a specific method for each
// respective class of modules.
void graphMapper::performActionsOverAllModules(
  region_to_modules_map_t &available_sr_modules,
  reconfigurableRegions &rr_contents,
  int long &least_than_scoreboard,
  std::shared_ptr<graphNode> &least_than_reference,
  sr_action_t sr_action,
  rr_action_t rr_action
) {

  // Loop through all static regions.
  for (auto &sr_it : available_sr_modules) {

    // Loop through all static modules.
    for (auto &sr_module_it : sr_it.second) {

      // Perform SR-specific module action.
      sr_action(sr_module_it, _execution_counter, least_than_scoreboard, least_than_reference);
    }
  }

  // Perform rr_action for every module contained by a reconfigurable region.
  rr_contents.performActionOverAllRegions(
    rr_action,
    _execution_counter,
    least_than_scoreboard,
    least_than_reference
  );
}
