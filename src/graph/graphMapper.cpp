
#include "graphMapper.h"

/* PUBLIC */

void graphMapper::mapRegionsToGraphNodesAndProduceTraces(
  const std::vector<std::shared_ptr<graph>> &graphs,
  ip_params_map_t &ip_params_map,
  region_to_avail_modules_t &available_sr_modules,
  region_to_avail_modules_t &available_rr_modules,
  ip_to_capable_modules_map_t &ip_to_capable_modules_map,
  moduleSelectionType module_selection_method
) {

  // TODO: This should be derived from configuration parameters, otherwise set to 0.
  auto use_time_as_random_seed = false;
  unsigned random_seed;

  if (use_time_as_random_seed) {
    random_seed = (unsigned)time(0);
  } else {
    random_seed = 7285;
  }

  // Feed the seed to the pseudo-random number generator.
  srand(random_seed);

  auto trace_file_name = input_file_;
  auto dot_pos = input_file_.find_last_of('.');

  // If there is an extension on the file name only use the name before the extension.
  if (dot_pos != std::string::npos) {
    trace_file_name = input_file_.substr(0, dot_pos);
  }

  unsigned graph_id = 0;

  // Use specified mapping approach.
  switch (module_selection_method) {

    // Random selection of available module.
    case moduleSelectionType::random:

      // Perform mapping activities for each graph.
      for (const auto &it : graphs) {
        graph_id++;

        auto all_top_level_nodes = it->getAllTopLevelNodes();

        std::cout << "\n\n>>> Beginning new graph mapping. <<<\n\n";

        // Iteratively travel from every top level node to map every node with a pseudo-randomly chosen region.
        auto traces = mapRegionsToGraphNodesAndProduceTracesIterativeBreadthFirst(
          all_top_level_nodes,
          ip_params_map,
          available_sr_modules,
          available_rr_modules,
          ip_to_capable_modules_map
        );

        auto new_file_name = trace_file_name + "_" + std::to_string(graph_id);

        // Create new trace file (overwrite if necessary) and store traces.
        auto trace_file_handler = fileWriter(new_file_name);
        trace_file_handler.deleteIfExists();

        // Iterate over all produced traces and print a line in the resultant trace file.
        //for (unsigned long i = 0; i < traces.size(); i++) {
        for (const auto trace : traces) {
          //auto trace = traces.at(i);
          auto trace_event = trace->getHumanFriendlyDisplayString();
          trace_file_handler.addSingleLineToEof(trace_event);
        }
      }
      break;

    default:
      throw std::runtime_error("The chosen module mapping method is not yet supported.");
  }

  if (DEBUG_MAP_REGIONS) {
    auto debug_helper = debugHelper();
    debug_helper.debugMapRegions(graphs);
  }
}

/* PRIVATE */

//      all traces are of the following format:
//        <containing region ID>,
//        <module ID>,
//        <request time>,           // when did the application ask?
//        <load start time>,        // when did the library start sending the bitstream (library could be busy servicing other request)
//        <load fulfillment time>,  // when did the bitstream actually get completely loaded
//        <execution time>,         // total clock cycles (in its' clock region) required to finish execution
//
//      What happens when the FPGA application needs some IP
//        1) the need is generated by succeeding prior tasks
//        2) if the ip can fit anywhere the ICAP starts to draw it in
//          - if it can't fit in anywhere the application will call for it when it can free up a suitable space
//        3) after the region has been loaded with the module it begins executing
//        4) once the module is done it goes idle (if there are no other tasks for that ip) or it executes another task (for the same ip)
std::vector<std::shared_ptr<applicationTrace>> graphMapper::mapRegionsToGraphNodesAndProduceTracesIterativeBreadthFirst(
  std::deque<std::shared_ptr<graphNode>> available_nodes,
  ip_params_map_t &ip_params_map,
  region_to_avail_modules_t &available_sr_modules,
  region_to_avail_modules_t &available_rr_modules,
  ip_to_capable_modules_map_t ip_to_capable_modules_map
) {
  auto resultant_traces = std::vector<std::shared_ptr<applicationTrace>>();

  unsigned long long execution_counter = 0;

  // Create a container vector for the contents of each reconfigurable region.
  std::unordered_map<unsigned, std::shared_ptr<availableModule>> rr_contents;
  for (auto i = 0; i < available_rr_modules.size(); i++) {
    rr_contents.insert(std::make_pair(i, std::shared_ptr<availableModule>(new availableModule(0, 0))));
  }

  std::unordered_map<std::string, std::shared_ptr<graphNode>> executing_nodes;

  // Priority queue for keeping track of which node with at least one dependency is the nearest
  // to having a dependency completed.
  std::unordered_map<std::string, std::shared_ptr<graphNode>> nodes_with_pending_dependencies;

  unsigned long trace_id = 0;

  // Repeatedly map each node until the lists of available nodes and nodes with pending dependencies
  // are entirely consumed.
  while (!available_nodes.empty() || !nodes_with_pending_dependencies.empty()) {

    std::cout << "\n\n\n-----------------------------------\nCC Count: " << execution_counter << "\n";

    std::cout << "\nThere are " << available_nodes.size() << " available nodes, "
              << executing_nodes.size() << " executing nodes, and "
              << nodes_with_pending_dependencies.size() << " nodes waiting on dependencies.\n";

    // Note, these are inconsequential variables supplied to meet the argument signature requirements
    // of the "performActionsOverAllModules" method.
    int long placeholder0;
    std::shared_ptr<graphNode> placeholder1;

    // Iterate over all modules and update their execution contexts.
    performActionsOverAllModules(
      available_sr_modules,
      rr_contents,
      execution_counter,
      placeholder0,
      placeholder1,
      moduleIterationActions::updateExecutionContextSr,
      moduleIterationActions::updateExecutionContextRr
    );

    std::vector<std::string> node_keys_to_remove_from_exe_nodes;

    // Remove all completed nodes from the executing list.
    for (auto &node_it : executing_nodes) {
      if (node_it.second->getNodeIsComplete()) {
        node_keys_to_remove_from_exe_nodes.push_back(node_it.first);
      }
    }

    for (auto &node_it : node_keys_to_remove_from_exe_nodes) {
      executing_nodes.erase(node_it);
    }

    // Try to schedule every available task.
    for (unsigned i = 0; i < available_nodes.size(); i++) {

      // Get a node and pop the deque.
      auto node = available_nodes.front();
      available_nodes.pop_front();

      std::cout << "\nScheduling task '" << node->getNodeId();

      unsigned node_ip_id = node->getIpId();

      std::cout << "' (with ip" << node_ip_id << ")\n";

      // Search the IP-to-capable modules_map for the corresponding entry to this IP.
      auto capable_modules_entry = ip_to_capable_modules_map.find(node_ip_id);
      if (capable_modules_entry == ip_to_capable_modules_map.end()) {

        std::cout << "ERROR: While mapping modules to graph nodes there was an IP (ID = "
                  << node_ip_id
                  << ") that did not have a corresponding entry in the IP-to-capable "
                  << "modules_map\n\n";
        exit(-1);
      }

      auto &capable_modules = capable_modules_entry->second;
      auto modules_under_consideration = std::vector<std::shared_ptr<availableModule>>(capable_modules);

      unsigned total_modules = capable_modules.size();
      bool module_found = false;

      std::cout << "\tthere are " << total_modules << " total capable modules for the job. { ";
      for (auto &it : modules_under_consideration) {
        std::cout << it->getHumanReadableId() << ", ";
      }
      std::cout << "}\n";

      // Keep searching until a module is chosen or all options are exhausted.
      while (total_modules != 0 && !module_found) {

        // Pick a random capable module to run the task.
        unsigned random_module_index = rand() % static_cast<unsigned>(total_modules);
        auto &random_module = modules_under_consideration[random_module_index];

        bool is_not_static = !random_module->getIsStatic();
        unsigned region_id = random_module->getRegionId();

        auto matching_rr = rr_contents.find(region_id);

        // If the module is already busy remove it from consideration.
        if (random_module->getIsActive()) {

          std::cout << "\t'"
                    << random_module->getHumanReadableId()
                    << "' was removed from mapping consideration because it was busy.\n";
          std::cout << "\tthere were "
                    << modules_under_consideration.size()
                    << " capable modules and the one to be removed is at index "
                    << random_module_index << "\n";

          // Remove the unfit random module from consideration.
          modules_under_consideration.erase(modules_under_consideration.begin() + random_module_index);
          total_modules--;

        // If the random module is a module that only works in a busy reconfigurable region remove it from consideration.
        } else if (is_not_static && matching_rr->second->getIsActive()) {

          std::cout << "\t'"
                    << random_module->getHumanReadableId()
                    << "' was removed from mapping consideration because the region is must occupy is busy.\n";
          std::cout << "\tthere were "
                    << modules_under_consideration.size()
                    << " capable modules and the one to be removed is at index "
                    << random_module_index
                    << "\n";

          // remove the unfit random module from consideration
          modules_under_consideration.erase(modules_under_consideration.begin() + random_module_index);
          total_modules--;

        // If the module is ready to accept a task then mark the module as busy and add a trace.
        } else {

          std::cout << "\t'"
                    << random_module->getHumanReadableId()
                    << "' is free and able to accept the task of IP "
                    << node_ip_id
                    << ".\n";

          // Mark as active.
          random_module->setIsActive(true);

          // Insert into the list of executing nodes
          executing_nodes.insert(
            std::pair<std::string, std::shared_ptr<graphNode>>(node->getNodeId(), node)
          );

          // If the module belongs to a reconfigurable region then in needs to now occupy its' container.
          if (is_not_static) {
            matching_rr->second = random_module;
          }
          
          // Assign the node to the module.
          random_module->setCurrentTask(node);

          // Increment the execution counter by one to simulate a restriction wherein a task can only be requested per cycle.
          execution_counter++;
          std::cout << "\tCC Count incremented to " << execution_counter << "\n";

          // Choose an execution latency dependent on the IP being mapped to the module.
          auto ip_param = ip_params_map[node_ip_id];
          unsigned random_latency_noise = rand() % ip_param.upper_tolerance_ + ip_param.lower_tolerance_;
          unsigned execution_latency = ip_param.latency_ + random_latency_noise;

          // Set the execution latency for the node.
          node->beginExecution(execution_latency, execution_counter); //, random_module);

          // TODO: Figure out how to derive the trace's dependent traces and supply them to the object.
          std::vector<std::shared_ptr<applicationTrace>> dependent_traces = node->getDependentApplicationTraces();

          // Create the corresponding trace and add it to the result.
          auto confirmed_trace = std::shared_ptr<applicationTrace>(
            new applicationTrace(
              trace_id++,
              node_ip_id,
              random_module,
              execution_counter,
              execution_latency,
              dependent_traces
            )
          );
          resultant_traces.push_back(confirmed_trace);

          // Assign newly created application trace to the task node for dependency tracking.
          node->setApplicationTrace(confirmed_trace);

          // Indicate a viable module was found and that a mapping has occurred this loop iteration.
          module_found = true;

          // Add successor nodes to available nodes if it is not mapped to a region and all dependencies are satisfied.
          auto successor_nodes = node->getSuccessorNodes();

          std::cout << "\thas " << successor_nodes.size() << " successors: ";

          for (auto it = successor_nodes.begin(); it != successor_nodes.end(); ++it) {

            std::string node_id = (*it)->getNodeId();
            std::cout << "'" << node_id << "' (ip" << (*it)->getIpId() << ") [";

            // If all dependencies are now satisfied then add this successor node to the list of available nodes.
            if ((*it)->allDependenciesSatisfied()) {

              std::cout << "ready to execute";
              available_nodes.push_back(*it);

            // If the successor node still has pending dependencies then...
            }  else {
              std::cout << "outstanding dependencies";

              auto vector_presence = nodes_with_pending_dependencies.find(node_id);

              if (vector_presence == nodes_with_pending_dependencies.end()) {
                nodes_with_pending_dependencies.insert(std::pair<std::string, std::shared_ptr<graphNode>>(node_id, *it));
              }
            }

            std::cout << "], ";
          }
          std::cout << "\n";
        }

      } // /Find available module loop.

      // If a suitable module was not found for the task then the node must be re-enqueued.
      if (total_modules == 0) {
        std::cout << "\tThere were no available regions to accept the task.  Putting back into available_nodes for later.\n";

        available_nodes.push_back(node);

        // Need to move the execution context forward if there aren't any nodes with pending dependencies to move the context forward.
        if (nodes_with_pending_dependencies.empty()) {
          advanceExecutionContextByEarliestFinishingTask(available_sr_modules, rr_contents, execution_counter);
        }
      }

    } // /available_nodes for loop.

    // Only continue if there are nodes with pending dependencies.
    if (nodes_with_pending_dependencies.empty()) {
      continue;
    }

    std::cout << "\nMoving on to the pending dependencies...\npending dep nodes: ("
              << nodes_with_pending_dependencies.size()
              << " total) = { ";

    for (auto it = nodes_with_pending_dependencies.begin(); it != nodes_with_pending_dependencies.end(); ++it) {
      std::cout << (*it).first;
      if (it != nodes_with_pending_dependencies.end()) {
        std::cout << ", ";
      }
    }
    std::cout << " }";

    // Start off with the largest possible value.
    int long least_than_scoreboard = std::numeric_limits<int long>::max();

    std::shared_ptr<graphNode> least_than_reference;
    std::unordered_map<std::string, std::shared_ptr<graphNode>>::iterator chosen_pending_node_it;

    bool pending_node_chosen = false;

    // Loop through the priority queue's underlying deque and update the execution context.
    for (
      auto it = nodes_with_pending_dependencies.begin();
      it != nodes_with_pending_dependencies.end();
      ++it
    ) {

      auto node_ptr = (*it).second;

      std::cout << "\n\t" << (*it).first << " relationships with... ("
                << ((*it).second->getNodeIsExecuting() ? "OMG IS executing, " : "not executing, ")
                << ((*it).second->getNodeIsComplete() ? "OMG IS completed)\n" : "not complete)\n");

      std::vector<std::shared_ptr<graphNode>> predecessor_nodes = node_ptr->getPredecessorNodes();

      // Loop through all of the waiting node's dependency nodes and update their execution context to see if this node is ready to go.
      for (auto it2 = predecessor_nodes.begin(); it2 != predecessor_nodes.end(); ++it2) {

        std::cout << "\n\t\t* " << (*it2)->getNodeId() << "; ("; // would require " << << " cycles to complete\n";

        std::cout << ((*it2)->getNodeIsExecuting() ? "OMG IS executing, " : "not executing, ")
                  << ((*it2)->getNodeIsComplete() ? "OMG IS completed)\n" : "not complete)\n");

        // If the dependency has been executing then update its' execution context.
        // TODO: Is this necessary anymore since this is in the available_nodes for loop?
        if ((*it2)->getNodeIsExecuting() || (*it2)->getNodeIsComplete()) {

          std::cout << "\t\tcycles_remaining_ before recalculation: "
                    << (*it2)->getCyclesRemaining()
                    << "\n";

          // Update the node's execution context.
          int long cycles_remaining = (*it2)->adjustExecutionLatencyByContextUpdate(execution_counter);

          std::cout << "\n\t\t" << cycles_remaining << " < " << least_than_scoreboard << "\n";
          if (cycles_remaining < least_than_scoreboard) {

            bool this_node_may_be_chosen = true;

            // If cycles remaining are 0, then all other dependencies must be 0 as well.
            // Otherwise the 0 option will always be chosen introducing deadlock.
            if (cycles_remaining == 0) {
              std::cout << "\t\t\tA zero-remaining option has arisen.  This option may be chosen if all other dependencies are ready to go.\n";

              // TODO: There appears to be a serious problem with this loop.  Let's say you have two
              // predecessors.  If the first one reaches the "adjust execution latency" code, but the
              // second one doesn't, then it2 will not be chosen and the first it3 will be left in an
              // advanced state.  But at the same time, I think I might be wrong and it probably
              // doesn't matter.  Try to create some counter example.
              // THE FIX: Split the adjustExecutionLatencyByContextUpdate into 'calculate' and
              // 'adjust' functions.  Only perform the adjust if you actually choose.  And if you
              // are going to choose a zero, make sure if there are other zeros that the one you choose
              // has the lowest cost for all predecessors (I've been drinking - sorry if this doesn't
              // make complete sense).
              // Or maybe we need to adjust all of the predecessor nodes?  And just remember which one
              // is chosen, if one is chosen.
              for (auto it3 = predecessor_nodes.begin(); it3 != predecessor_nodes.end(); ++it3) {

                std::cout << "\t\t\t\t'" << (*it3)->getNodeId() << "'";

                if (!(*it3)->getNodeIsExecuting() && !(*it3)->getNodeIsComplete()) {

                  std::cout << " has not even begun to execute; disqualified.\n";
                  this_node_may_be_chosen = false;
                  break;
                }

                int long cy_remaining = (*it3)->adjustExecutionLatencyByContextUpdate(execution_counter);

                std::cout << " has " << cy_remaining << " remaining cycles";

                if (cy_remaining > 0) {
                  std::cout << "... This one is disqualified.\n";
                  this_node_may_be_chosen = false;
                  break;
                }
                std::cout << "\n";
              }
            }

            if (this_node_may_be_chosen) {
              std::cout << "\t\t\tPICKED\n";

              least_than_scoreboard = cycles_remaining;

              least_than_reference = *it2;
              chosen_pending_node_it = it;
              pending_node_chosen = true;
            }
          }

          // If the dependency has not begun executing then do not perform a context update.
        } else {
          std::cout << " still waiting on its' own dependencies to clear.\n";
        }
      }
    }

    // If a pending node was found to be the soonest dependency then fast forward using it.
    if (pending_node_chosen) {

      std::cout << "\n\tPNC: soonest to finish has only " << least_than_scoreboard << " remaining\n";

      // Fast-forward execution context if the execution of the dependency has not completed yet.
      if (least_than_scoreboard > 0)  {
        execution_counter += least_than_scoreboard;
        std::cout << "\tCC Count incremented to " << execution_counter << "\n";
      }

      std::cout << "\nNEXT EXE CC = " << execution_counter << "\n";

      std::cout << "TELL ME ABOUT YOURSELF least_than_reference: ";
      std::cout << least_than_reference->getNodeId() << " (ip" << least_than_reference->getIpId() << ")\n";

      std::cout << "TELL ME ABOUT YOURSELF chosen_pending_node_it: ";
      std::cout << (*chosen_pending_node_it).second->getNodeId() << " (ip" << (*chosen_pending_node_it).second->getIpId() << ")\n";

      // Mark node as completed if it has not already been done so.
      if (!least_than_reference->getNodeIsComplete()) {

        std::cout << "Marking least_than_reference node '" << least_than_reference->getNodeId()
                  << "' as complete since it has not been done so yet.\n";

        least_than_reference->setNodeIsComplete();
      }

      // If the node no longer has any dependencies then remove it from the pending dependency list and get added to available nodes.
      if ((*chosen_pending_node_it).second->allDependenciesSatisfied()) {

        std::cout << "Removing chosen_pending_node_it node'" << (*chosen_pending_node_it).second->getNodeId()
                  << "' from the nodes_with_pending_dependencies list and adding to available_nodes list.\n";

        available_nodes.push_back((*chosen_pending_node_it).second);
        nodes_with_pending_dependencies.erase(chosen_pending_node_it);
      }

      // If no pending node was found to be the soonest dependency to finish then choose an executing node
      // from the executing_nodes list with the shortest remaining execution time to fast forward.
    } else {
      advanceExecutionContextByEarliestFinishingTask(available_sr_modules, rr_contents, execution_counter);
    }
  }

  std::cout << "--------------------------------------------------------------------------------------\n\n"
            << ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> SIMULATION COMPLETE! <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n";

  unsigned long long placeholder0;
  int long placeholder1;
  std::shared_ptr<graphNode> placeholder2;

  // Iterate over all modules and set them to inactive status.
  performActionsOverAllModules(
    available_sr_modules,
    rr_contents,
    placeholder0,
    placeholder1,
    placeholder2,
    moduleIterationActions::setNotActiveSr,
    moduleIterationActions::setNotActiveRr
  );

  std::cout << "== Produced Traces:\n";
  for (auto trace_it = resultant_traces.begin(); trace_it != resultant_traces.end(); ++trace_it) {
    (*trace_it)->printHumanFriendlyDisplay();
  }

  return resultant_traces;
}

// CHECK BELOW COMMENTS

void graphMapper::advanceExecutionContextByEarliestFinishingTask(
  region_to_avail_modules_t &available_sr_modules,
  std::unordered_map<unsigned, std::shared_ptr<availableModule>> &rr_contents,
  unsigned long long &execution_counter
) {

  // start off with the largest possible value
  int long least_than_scoreboard = std::numeric_limits<int long>::max();

  std::shared_ptr<graphNode> least_than_reference;

  std::cout << "Some volues : " << execution_counter << " and " << least_than_scoreboard << "\n";

  // loop through all modules to find the module with the shortest remaining execution time
  performActionsOverAllModules(
    available_sr_modules,
    rr_contents, execution_counter,
    least_than_scoreboard,
    least_than_reference,
    moduleIterationActions::updateScoreboardSr,
    moduleIterationActions::updateScoreboardRr
  );

  std::cout << "\n\tsoonest to finish has only " << least_than_scoreboard << " remaining\n";

  // fast-forward execution context if the execution of the dependency has not completed yet.
  if (least_than_scoreboard > 0) {
    execution_counter += least_than_scoreboard;
    std::cout << "\tCC Count incremented to " << execution_counter << "\n";
  }

  std::cout << "\nEXE CC = " << execution_counter << "\n";

  std::cout << "TELL ME ABOUT YOURSELF least_than_reference: "
            << least_than_reference.get()
            << std::endl
            << std::flush;

  std::cout << least_than_reference->getNodeId() << " (ip" << least_than_reference->getIpId() << ")\n";

  // mark node as completed if it has not already been done so
  if (!least_than_reference->getNodeIsComplete()) {

    std::cout << "Marking least_than_reference node '"
              << least_than_reference->getNodeId()
              << "' as complete since it has not been done so yet.\n";

    least_than_reference->setNodeIsComplete();
  }
}

/////////////////
// TODO: F.60: Prefer T* over T& when "no argument" is a valid option
/////////////////

// Loops through all static modules and RR content modules executing a specific method for each respective classes of modules.
void graphMapper::performActionsOverAllModules(
  region_to_avail_modules_t &available_sr_modules,
  std::unordered_map<unsigned, std::shared_ptr<availableModule>> &rr_contents,
  unsigned long long &execution_counter,
  int long &least_than_scoreboard,
  std::shared_ptr<graphNode> &least_than_reference,
  sr_action_t sr_action,
  rr_action_t rr_action
) {

  // Loop through all static regions.
  for (auto &sr_it : available_sr_modules) {

    // Loop through all static modules, update their execution contexts, free any modules that are no longer busy.
    for (auto &sr_module_it : sr_it.second) {

      // Perform SR-specific module action
      sr_action(sr_module_it, execution_counter, least_than_scoreboard, least_than_reference);
    }
  }

  // Loop through all reconfigurable regions, update their execution contexts, free any regions that are no longer busy.
  for (auto &rr_it : rr_contents) {

    auto rr_id = rr_it.first;
    auto &rr_module = rr_it.second;

    // Perform RR-specific module action.
    rr_action(rr_id, rr_module, execution_counter, least_than_scoreboard, least_than_reference);
  }
}
